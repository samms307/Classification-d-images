# üê∂üê± Classification supervis√©e d'images de chiens et de chats  

## Pr√©sentation  
Ce projet se concentre sur la classification supervis√©e d'images de chiens et de chats.  

Nous avons constitu√© un ensemble de donn√©es comprenant **1 028 images pour chaque classe (chiens et chats)** soit un total de **2 058 images** extraites d'un ensemble plus vaste de **25 000 images**.  

Les donn√©es utilis√©es dans ce projet peuvent √™tre t√©l√©charg√©es √† l'adresse suivante : üîó [Microsoft Dataset](https://www.microsoft.com/en-us)  


## üéØ **Objectifs**
L'objectif principal de ce projet est de d√©velopper un algorithme capable de classer correctement une nouvelle image en tant que chien ou chat.

Pour cela, nous avons compar√© trois architectures de r√©seaux de neurones :
- Perceptron Multi-Couches (MLP)
- R√©seau de Neurones Convolutifs (CNN)
- Mod√®le pr√©-entra√Æn√© VGG16

L‚Äôanalyse s‚Äôest port√©e sur la pr√©cision, le temps d'entra√Ænement et la complexit√© afin de d√©terminer quelle architecture offre les meilleures performances.


# üìà **√âtapes Cl√©s du Projet**

### 1Ô∏è‚É£ **Pr√©traitement des Donn√©es**

Le pr√©traitement des images a √©t√© effectu√© via un pipeline automatis√©, incluant plusieurs √©tapes essentielles :

- **S√©paration des donn√©es en trois ensembles** : entra√Ænement, validation et test.
- **Redimensionnement** des images pour assurer une taille uniforme.
- **Normalisation** des pixels afin d'am√©liorer la convergence du mod√®le.
- **Nettoyage des donn√©es** incluant :
    - Uniformisation des canaux de couleur (conversion en RGB si n√©cessaire).
    - Gestion des images floues pour garantir la qualit√© des entr√©es.
  

### 2Ô∏è‚É£ **Entra√Ænement des Mod√®les**

Apr√®s le pr√©traitement, nous avons entra√Æn√© et compar√© trois architectures de r√©seaux de neurones :

- **Perceptron Multi-Couches (MLP)** : d√©velopp√© **from scratch** pour servir de baseline et √©valuer les performances des mod√®les plus avanc√©s.
- **R√©seau de Neurones Convolutifs (CNN)** : √©galement d√©velopp√© **from scratch**, con√ßu sp√©cifiquement pour l‚Äôanalyse d'images.
- **Mod√®le pr√©-entra√Æn√© VGG16** : exploit√© via **deux strat√©gies de transfert d'apprentissage** :  
  - **Transfert pur** : seule la derni√®re couche est modifi√©e, tandis que les couches pr√©existantes de VGG16 sont conserv√©es et gel√©es.  
  - **Fine-tuning** : certaines couches de VGG16 sont d√©gel√©es et r√©ajust√©es pour mieux s'adapter √† notre t√¢che sp√©cifique.

L‚Äôentra√Ænement a √©t√© r√©alis√© avec les √©l√©ments suivants comme base et d'autres √©lements selon les besoins sp√©cifiques de chaque mod√®le :  
- ‚úÖ Optimiseur 
- ‚úÖ Fonction de perte 
- ‚úÖ Taux d‚Äôapprentissage



### 3Ô∏è‚É£ **√âvaluation des Performances (Entra√Ænement/Validation et sur le Test)**

L‚Äôobjectif principal de cette √©tape √©tait de s√©lectionner le mod√®le le plus performant et d‚Äô√©valuer sa capacit√© √† g√©n√©raliser sur des donn√©es non vues.

#### **3.1 √âvaluation sur les Ensembles d'Entra√Ænement et de Validation** :
- S√©lection du meilleur mod√®le en fonction de la **combinaison optimale de la perte qui diminue** et de la **pr√©cision qui augmente** sur l'ensemble de validation. Cette √©volution conjointe assure que le mod√®le g√©n√©ralise bien, apprenant √† pr√©dire correctement tout en √©vitant le surapprentissage.

#### **3.2 √âvaluation sur l‚ÄôEnsemble de Test** :
- Utilisation de la **matrice de confusion** pour analyser les erreurs de classification (faux positifs, faux n√©gatifs).
- Calcul et analyse de la **courbe ROC** et de l‚Äô**AUC** pour mesurer la capacit√© du mod√®le √† discriminer efficacement entre les classes.


 
## üõ†Ô∏è **Outils et Technologies**

- **Langage** : Python
- **Biblioth√®ques** : TensorFlow, Keras, OpenCV

